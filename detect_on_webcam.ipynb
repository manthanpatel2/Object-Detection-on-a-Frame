{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper_funcs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time \n",
    "import gluoncv as gcv\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 people detected.\n",
      "[]\n",
      "[]\n",
      "2 people detected.\n",
      "[0.9982643, 0.98188883]\n",
      "[[171, 152, 1335, 597], [300, -3, 1319, 195]]\n",
      "2 people detected.\n",
      "[0.9979621, 0.96954757]\n",
      "[[162, 148, 1340, 602], [290, -3, 1320, 202]]\n",
      "2 people detected.\n",
      "[0.9984687, 0.9619786]\n",
      "[[226, 193, 1306, 596], [289, -3, 1321, 207]]\n",
      "2 people detected.\n",
      "[0.99868315, 0.98072547]\n",
      "[[184, 159, 1339, 595], [296, -3, 1313, 200]]\n",
      "2 people detected.\n",
      "[0.99786144, 0.9770967]\n",
      "[[174, 154, 1333, 598], [304, -2, 1312, 201]]\n",
      "2 people detected.\n",
      "[0.99874735, 0.9869394]\n",
      "[[187, 159, 1330, 592], [325, 1, 1301, 192]]\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "time.sleep(1)\n",
    "while True:\n",
    "    _,image = video.read()\n",
    "    input_w, input_h = 416, 416\n",
    "    shape_i = (input_w, input_h)\n",
    "    image_w, image_h, layers = image.shape\n",
    "    image_r = cv2.resize(image, shape_i)\n",
    "    image_arr = img_to_array(image_r)\n",
    "    image_arr = image_arr.astype('float32')\n",
    "    image_arr /= 255.0\n",
    "    image_arr = expand_dims(image_arr, 0)\n",
    "    \n",
    "    predicted_result = model.predict(image_arr)\n",
    "    \n",
    "    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "\n",
    "    threshold_val = 0.6\n",
    "    boxes = list()\n",
    "    for i in range(len(predicted_result)):\n",
    "        # decode the output of the network\n",
    "        boxes += get_network_output(predicted_result[i][0], anchors[i], threshold_val, input_h, input_w)\n",
    "    \n",
    "    new_w, new_h = input_w, input_h\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (input_w - new_w)/2./input_w, float(new_w)/input_w\n",
    "        y_offset, y_scale = (input_h - new_h)/2./input_h, float(new_h)/input_h\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "        \n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "        for c in range(nb_class):\n",
    "            sorted_data = np.argsort([-box.classes[c] for box in boxes])\n",
    "            for i in range(len(sorted_data)):\n",
    "                index_i = sorted_data[i]\n",
    "                if boxes[index_i].classes[c] == 0: continue\n",
    "                for j in range(i+1, len(sorted_data)):\n",
    "                    index_j = sorted_data[j]\n",
    "                    box1, box2 = boxes[index_i], boxes[index_j]\n",
    "                    intersect_width = chk_for_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "                    intersect_height = chk_for_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "                    intersect = intersect_width * intersect_height\n",
    "                    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "                    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "                    union = w1*h1 + w2*h2 - intersect\n",
    "                    if float(intersect) / union >= 0.5:\n",
    "                        boxes[index_j].classes[c] = 0\n",
    "    \n",
    "    labels = [\"person\"]\n",
    "    \n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    for box in boxes:\n",
    "        for i in range(len(labels)):\n",
    "            if box.classes[i] > threshold_val:\n",
    "                v_boxes.append([box.ymin, box.xmin, box.ymax, box.xmax])\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i])\n",
    "                \n",
    "    num_people = len(v_boxes)\n",
    "    if num_people == 1:\n",
    "        text= '{} person detected.'.format(num_people)\n",
    "    else:\n",
    "        text = '{} people detected.'.format(num_people)\n",
    "    print(text)\n",
    "    color = (0,0,255)\n",
    "    thickness=2\n",
    "    fontScale=1\n",
    "    org = (120,450)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    countme = cv2.putText(image, text, org, font, fontScale,color, thickness, cv2.LINE_AA, False) \n",
    "    \n",
    "    class_ids,scores,bounding_boxes = [0]*num_people, v_scores, v_boxes\n",
    "    print(scores)\n",
    "    print(bounding_boxes)\n",
    "    \n",
    "    for i in range(len(bounding_boxes)):\n",
    "\n",
    "        score = scores[i]\n",
    "        if score > threshold_val:\n",
    "\n",
    "            left = bounding_boxes[i][0]\n",
    "            top = bounding_boxes[i][1]\n",
    "            right = bounding_boxes[i][2]\n",
    "            bottom = bounding_boxes[i][3]\n",
    "\n",
    "            #draw a red rectangle around detected objects\n",
    "            cv2.rectangle(image, (int(left), int(top)), (int(top), int(bottom)), (0, 0, 255), thickness=2)\n",
    "    \n",
    "#     preds = gcv.utils.viz.cv_plot_bbox(image,bounding_boxes,scores,class_ids,class_names = labels, scale=1)\n",
    "    cv2.imshow('result',countme)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
